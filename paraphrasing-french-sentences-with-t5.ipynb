{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nizarkarkar/paraphrasing-with-fine-tuning-t5-in-french?scriptVersionId=142453281\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-08T08:37:56.151352Z","iopub.execute_input":"2023-09-08T08:37:56.151859Z","iopub.status.idle":"2023-09-08T08:37:56.178864Z","shell.execute_reply.started":"2023-09-08T08:37:56.151826Z","shell.execute_reply":"2023-09-08T08:37:56.177927Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/modelt5/t5-small_cached_2561809\n/kaggle/input/parphrase/para.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \ndataset_df=pd.read_excel('/kaggle/input/parphrase/para.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:37:56.180779Z","iopub.execute_input":"2023-09-08T08:37:56.181258Z","iopub.status.idle":"2023-09-08T08:37:56.836547Z","shell.execute_reply.started":"2023-09-08T08:37:56.181224Z","shell.execute_reply":"2023-09-08T08:37:56.835404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install simpletransformers datasets tqdm pandas\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:37:56.841259Z","iopub.execute_input":"2023-09-08T08:37:56.842076Z","iopub.status.idle":"2023-09-08T08:38:26.261721Z","shell.execute_reply.started":"2023-09-08T08:37:56.842038Z","shell.execute_reply":"2023-09-08T08:38:26.260555Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting simpletransformers\n  Downloading simpletransformers-0.64.3-py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.31.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2023.6.3)\nCollecting transformers>=4.31.0 (from simpletransformers)\n  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.11.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nCollecting seqeval (from simpletransformers)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.12.3)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.13.3)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.5)\nCollecting streamlit (from simpletransformers)\n  Downloading streamlit-1.26.0-py2.py3-none-any.whl (8.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.1.99)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2023.5.7)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.3.1)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.1.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.0.1)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.6.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.7.0)\nRequirement already satisfied: pillow<10,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\nRequirement already satisfied: pympler<2,>=0.9 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.0.1)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.4.2)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.2)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nCollecting tzlocal<5,>=1.1 (from streamlit->simpletransformers)\n  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\nCollecting validators<1,>=0.2 (from streamlit->simpletransformers)\n  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\nCollecting pydeck<1,>=0.8 (from streamlit->simpletransformers)\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.3.2)\nCollecting watchdog>=2.1.5 (from streamlit->simpletransformers)\n  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.3.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.40.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit->simpletransformers) (3.15.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.15.1)\nCollecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit->simpletransformers)\n  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->simpletransformers) (2023.3)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=af89a995707f614ddf7a45237774cc387a12efbf1c2116c1cf5eb4240ef0303b\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: watchdog, validators, pytz-deprecation-shim, tzlocal, pydeck, transformers, seqeval, streamlit, simpletransformers\n  Attempting uninstall: tzlocal\n    Found existing installation: tzlocal 5.0.1\n    Uninstalling tzlocal-5.0.1:\n      Successfully uninstalled tzlocal-5.0.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed pydeck-0.8.0 pytz-deprecation-shim-0.1.0.post0 seqeval-1.2.2 simpletransformers-0.64.3 streamlit-1.26.0 transformers-4.33.1 tzlocal-4.3.1 validators-0.22.0 watchdog-3.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_df=pd.read_excel('/kaggle/input/parphrase/para.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:26.264802Z","iopub.execute_input":"2023-09-08T08:38:26.265285Z","iopub.status.idle":"2023-09-08T08:38:26.450956Z","shell.execute_reply.started":"2023-09-08T08:38:26.265247Z","shell.execute_reply":"2023-09-08T08:38:26.450054Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ndataset_df.columns = [\"input_text\",\"target_text\"]\ndataset_df[\"prefix\"] = \"paraphrase\"","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:26.452544Z","iopub.execute_input":"2023-09-08T08:38:26.452945Z","iopub.status.idle":"2023-09-08T08:38:26.465762Z","shell.execute_reply.started":"2023-09-08T08:38:26.452904Z","shell.execute_reply":"2023-09-08T08:38:26.464735Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from simpletransformers.t5 import T5Model\nfrom sklearn.model_selection import train_test_split\nimport sklearn","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:26.468113Z","iopub.execute_input":"2023-09-08T08:38:26.468481Z","iopub.status.idle":"2023-09-08T08:38:41.103118Z","shell.execute_reply.started":"2023-09-08T08:38:26.46843Z","shell.execute_reply":"2023-09-08T08:38:41.101548Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data,test_data = train_test_split(dataset_df,test_size=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:41.109362Z","iopub.execute_input":"2023-09-08T08:38:41.110691Z","iopub.status.idle":"2023-09-08T08:38:41.125989Z","shell.execute_reply.started":"2023-09-08T08:38:41.110645Z","shell.execute_reply":"2023-09-08T08:38:41.124859Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:41.13059Z","iopub.execute_input":"2023-09-08T08:38:41.132052Z","iopub.status.idle":"2023-09-08T08:38:41.156598Z","shell.execute_reply.started":"2023-09-08T08:38:41.132018Z","shell.execute_reply":"2023-09-08T08:38:41.155834Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             input_text  \\\n912         Mon grand-père tricote une écharpe colorée.   \n368          Ma grand-mère cuisine des plats délicieux.   \n1932  Ma mère prépare un délicieux gâteau pour mon a...   \n629   Les enfants sont le futur et méritent une éduc...   \n755   J'aime lire des poèmes apaisants pour me déten...   \n...                                                 ...   \n1952  Nous avons mangé une délicieuse pizza pour le ...   \n726            J'ai hâte de partir en vacances cet été.   \n1603          Il a remporté la compétition de natation.   \n1095                      La musique adoucit les mœurs.   \n248   Nous avons réservé une table au restaurant pou...   \n\n                                            target_text      prefix  \n912   Mon grand-père confectionne une écharpe aux co...  paraphrase  \n368   Des plats délicieux sont cuisinés par ma grand...  paraphrase  \n1932  À l'occasion de mon anniversaire, ma mère conf...  paraphrase  \n629   Pour bâtir l'avenir, il est primordial d'offri...  paraphrase  \n755   Pour me détendre, j'apprécie la lecture de poè...  paraphrase  \n...                                                 ...         ...  \n1952  Pour notre repas du soir, nous avons savouré u...  paraphrase  \n726   L'été approchant, j'éprouve une grande impatie...  paraphrase  \n1603  Il est sorti victorieux de la compétition de n...  paraphrase  \n1095  L'écoute de musique a un effet apaisant sur le...  paraphrase  \n248   Pour ce soir, nous avons effectué une réservat...  paraphrase  \n\n[1809 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>target_text</th>\n      <th>prefix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>912</th>\n      <td>Mon grand-père tricote une écharpe colorée.</td>\n      <td>Mon grand-père confectionne une écharpe aux co...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>Ma grand-mère cuisine des plats délicieux.</td>\n      <td>Des plats délicieux sont cuisinés par ma grand...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>1932</th>\n      <td>Ma mère prépare un délicieux gâteau pour mon a...</td>\n      <td>À l'occasion de mon anniversaire, ma mère conf...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>Les enfants sont le futur et méritent une éduc...</td>\n      <td>Pour bâtir l'avenir, il est primordial d'offri...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>J'aime lire des poèmes apaisants pour me déten...</td>\n      <td>Pour me détendre, j'apprécie la lecture de poè...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1952</th>\n      <td>Nous avons mangé une délicieuse pizza pour le ...</td>\n      <td>Pour notre repas du soir, nous avons savouré u...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>726</th>\n      <td>J'ai hâte de partir en vacances cet été.</td>\n      <td>L'été approchant, j'éprouve une grande impatie...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>1603</th>\n      <td>Il a remporté la compétition de natation.</td>\n      <td>Il est sorti victorieux de la compétition de n...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>La musique adoucit les mœurs.</td>\n      <td>L'écoute de musique a un effet apaisant sur le...</td>\n      <td>paraphrase</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>Nous avons réservé une table au restaurant pou...</td>\n      <td>Pour ce soir, nous avons effectué une réservat...</td>\n      <td>paraphrase</td>\n    </tr>\n  </tbody>\n</table>\n<p>1809 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"args = {\n    \"reprocess_input_data\": True,\n    \"overwrite_output_dir\": True,\n    \"max_seq_length\": 256,\n    \"num_train_epochs\": 4,\n    \"num_beams\": None,\n    \"do_sample\": True,\n    \"top_k\": 50,\n    \"top_p\": 0.95,\n    \"use_multiprocessing\": False,\n    \"save_steps\": -1,\n    \"save_eval_checkpoints\": True,\n    \"evaluate_during_training\": False,\n    'adam_epsilon': 1e-08,\n    'eval_batch_size': 6,\n    'fp_16': False,\n\n    'gradient_accumulation_steps': 16,\n    'learning_rate': 0.0003,\n    'max_grad_norm': 1.0,\n    'n_gpu': 1,\n    'seed': 42,\n    'train_batch_size': 6,\n    'warmup_steps': 0,\n    'weight_decay': 0.0\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:51.17228Z","iopub.execute_input":"2023-09-08T08:38:51.17272Z","iopub.status.idle":"2023-09-08T08:38:51.18455Z","shell.execute_reply.started":"2023-09-08T08:38:51.172681Z","shell.execute_reply":"2023-09-08T08:38:51.183615Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = T5Model(\"t5\",\"t5-small\", args=args,use_cuda=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:52.348408Z","iopub.execute_input":"2023-09-08T08:38:52.348769Z","iopub.status.idle":"2023-09-08T08:38:55.996132Z","shell.execute_reply.started":"2023-09-08T08:38:52.348737Z","shell.execute_reply":"2023-09-08T08:38:55.995245Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3854cb08b014ef39f2cd687f0ec8597"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1a57c49eec3424fa8789ee8e46b1f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3719552b8ced4535adc5d2a6eabcb29f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ee66b6fa1d42ed9d000d61873f776c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec519a786af4a3f859f1b19d60426ca"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}]},{"cell_type":"code","source":"model.train_model(train_data, eval_data=test_data, use_cuda=True,acc=sklearn.metrics.accuracy_score)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T08:38:55.998018Z","iopub.execute_input":"2023-09-08T08:38:55.998391Z","iopub.status.idle":"2023-09-08T10:56:09.159262Z","shell.execute_reply.started":"2023-09-08T08:38:55.998355Z","shell.execute_reply":"2023-09-08T10:56:09.158126Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1809 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d9cc510c2d444cfb819db1fed65a0d3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74098a746b704a0c8e64834ae73c3278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 4:   0%|          | 0/302 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c826cdba2d4deab4febfe2d412d9e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 4:   0%|          | 0/302 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe992380dd9d472e84104a677527284a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 4:   0%|          | 0/302 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ffa574d87b4e388592b1d1af471d1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 4:   0%|          | 0/302 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9df65a923fc48188beb19fa22bd0136"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(72, 1.2730146551815171)"},"metadata":{}}]},{"cell_type":"code","source":"from simpletransformers.t5 import T5Model\nfrom pprint import pprint\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:01:52.661058Z","iopub.execute_input":"2023-09-08T11:01:52.661435Z","iopub.status.idle":"2023-09-08T11:01:52.666045Z","shell.execute_reply.started":"2023-09-08T11:01:52.661405Z","shell.execute_reply":"2023-09-08T11:01:52.664878Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\nroot_dir = os.getcwd()\ntrained_model_path = os.path.join(root_dir,\"outputs\")\n     ","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:01:55.342482Z","iopub.execute_input":"2023-09-08T11:01:55.342924Z","iopub.status.idle":"2023-09-08T11:01:55.348184Z","shell.execute_reply.started":"2023-09-08T11:01:55.342892Z","shell.execute_reply":"2023-09-08T11:01:55.347148Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"args = {\n    \"overwrite_output_dir\": True,\n    \"max_seq_length\": 256,\n    \"max_length\": 50,\n    \"top_k\": 50,\n    \"top_p\": 0.95,\n    \"num_return_sequences\": 5,\n    \"num_beams\":1\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:01:58.479931Z","iopub.execute_input":"2023-09-08T11:01:58.480291Z","iopub.status.idle":"2023-09-08T11:01:58.485953Z","shell.execute_reply.started":"2023-09-08T11:01:58.480261Z","shell.execute_reply":"2023-09-08T11:01:58.485033Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trained_model = T5Model(\"t5\",trained_model_path,args=args,use_cuda=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:02:29.454705Z","iopub.execute_input":"2023-09-08T11:02:29.455626Z","iopub.status.idle":"2023-09-08T11:02:30.325238Z","shell.execute_reply.started":"2023-09-08T11:02:29.455578Z","shell.execute_reply":"2023-09-08T11:02:30.324245Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"prefix = \"paraphrase\"\n\npred = trained_model.predict([f\"{prefix}:Avez vous des mauvaises sentiments? .\"])\nfor i in pred :\n   print(i)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:02:46.362856Z","iopub.execute_input":"2023-09-08T11:02:46.363235Z","iopub.status.idle":"2023-09-08T11:02:48.913643Z","shell.execute_reply.started":"2023-09-08T11:02:46.363203Z","shell.execute_reply":"2023-09-08T11:02:48.912514Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ff502adad64762a85ea185edcec4a2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3786: FutureWarning: \n`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n`__call__` method to prepare your inputs and targets.\n\nHere is a short example:\n\nmodel_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n\nIf you either need to use different keyword arguments for the source and target texts, you should do two calls like\nthis:\n\nmodel_inputs = tokenizer(src_texts, ...)\nlabels = tokenizer(text_target=tgt_texts, ...)\nmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n\nSee the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\nFor a more complete example, see the implementation of `prepare_seq2seq_batch`.\n\n  warnings.warn(formatted_warning, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Decoding outputs:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2b2a2aa80274add90702433df65e872"}},"metadata":{}},{"name":"stdout","text":"['Avez-vous malsinué les sentiment Coronation I ne se prête pas?', 'Soyez-vous mécontent de vos mauvaises sentiments?', '.', 'Comment résonner en mauvaise santé?', '.']\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install language_tool_python","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:02:51.950925Z","iopub.execute_input":"2023-09-08T11:02:51.952108Z","iopub.status.idle":"2023-09-08T11:03:04.546957Z","shell.execute_reply.started":"2023-09-08T11:02:51.952061Z","shell.execute_reply":"2023-09-08T11:03:04.545715Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Collecting language_tool_python\n  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from language_tool_python) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from language_tool_python) (4.65.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (2023.5.7)\nInstalling collected packages: language_tool_python\nSuccessfully installed language_tool_python-2.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import language_tool_python","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:03:04.551171Z","iopub.execute_input":"2023-09-08T11:03:04.551486Z","iopub.status.idle":"2023-09-08T11:03:04.569523Z","shell.execute_reply.started":"2023-09-08T11:03:04.551457Z","shell.execute_reply":"2023-09-08T11:03:04.568488Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"tool=language_tool_python.LanguageTool('fr-FR')","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:03:08.275654Z","iopub.execute_input":"2023-09-08T11:03:08.276514Z","iopub.status.idle":"2023-09-08T11:03:17.89016Z","shell.execute_reply.started":"2023-09-08T11:03:08.276466Z","shell.execute_reply":"2023-09-08T11:03:17.888905Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Downloading LanguageTool 5.7: 100%|██████████| 225M/225M [00:03<00:00, 60.7MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def check_grammer(text):\n    matches=tool.check(text)\n    return len(matches)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:03:20.195755Z","iopub.execute_input":"2023-09-08T11:03:20.196283Z","iopub.status.idle":"2023-09-08T11:03:20.203893Z","shell.execute_reply.started":"2023-09-08T11:03:20.196238Z","shell.execute_reply":"2023-09-08T11:03:20.202927Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for i in pred[0]:\n    print(f\"the sentence is {i} with number of gammer mistaks equals to {check_grammer(i)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:05:20.058882Z","iopub.execute_input":"2023-09-08T11:05:20.059271Z","iopub.status.idle":"2023-09-08T11:05:23.319079Z","shell.execute_reply.started":"2023-09-08T11:05:20.059239Z","shell.execute_reply":"2023-09-08T11:05:23.31791Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"the sentence is Avez-vous malsinué les sentiment Coronation I ne se prête pas? with number of gammer mistaks equals to 4\nthe sentence is Soyez-vous mécontent de vos mauvaises sentiments? with number of gammer mistaks equals to 1\nthe sentence is . with number of gammer mistaks equals to 1\nthe sentence is Comment résonner en mauvaise santé? with number of gammer mistaks equals to 1\nthe sentence is . with number of gammer mistaks equals to 1\n","output_type":"stream"}]},{"cell_type":"code","source":"def select_the_most_efficient_sentence(prediction):\n    hash_map=dict()\n    for i in prediction[0]:\n        hash_map[i]=check_grammer(i)\n    most_efficient_sentence=min(hash_map, key=lambda k: hash_map[k])\n    return most_efficient_sentence\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:16:42.740394Z","iopub.execute_input":"2023-09-08T11:16:42.740823Z","iopub.status.idle":"2023-09-08T11:16:42.748963Z","shell.execute_reply.started":"2023-09-08T11:16:42.740779Z","shell.execute_reply":"2023-09-08T11:16:42.748024Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"select_the_most_efficient_sentence(pred)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:16:43.581655Z","iopub.execute_input":"2023-09-08T11:16:43.581998Z","iopub.status.idle":"2023-09-08T11:16:45.046021Z","shell.execute_reply.started":"2023-09-08T11:16:43.581969Z","shell.execute_reply":"2023-09-08T11:16:45.045016Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'Soyez-vous mécontent de vos mauvaises sentiments?'"},"metadata":{}}]},{"cell_type":"code","source":"def custom_pipeline(text):\n    prefix = \"paraphrase\"\n\n    pred = trained_model.predict([f\"{prefix}:{text}\"])\n    return select_the_most_efficient_sentence(pred)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-08T11:46:00.951991Z","iopub.execute_input":"2023-09-08T11:46:00.953114Z","iopub.status.idle":"2023-09-08T11:46:00.958919Z","shell.execute_reply.started":"2023-09-08T11:46:00.953072Z","shell.execute_reply":"2023-09-08T11:46:00.957886Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"custom_pipeline(\"J'ai hâte de partir en vacances cet été\")","metadata":{"execution":{"iopub.status.busy":"2023-09-08T12:03:13.155951Z","iopub.execute_input":"2023-09-08T12:03:13.157191Z","iopub.status.idle":"2023-09-08T12:03:16.492867Z","shell.execute_reply.started":"2023-09-08T12:03:13.157137Z","shell.execute_reply":"2023-09-08T12:03:16.491736Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267933c306db440cba934429b82e3bce"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Decoding outputs:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d39b47ebb7e496190e52a6e430f4d8e"}},"metadata":{}},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"\"En vacances cet été, j'ai hâte de ne manquer pas de me lancer en hâte.\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}